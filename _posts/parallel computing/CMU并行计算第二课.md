### 两个问题回顾

**1、为什么这几年单指令流性能很难提高？**

这里的单指令流其实就是流水线了，流水线也并不可能无限的提高性能。因为主要有以下三个方面的原因。

a)、因为存在数据冒险，所以我们并不能让流水线很繁忙。

b)、在深度的流水线中进行转发的成本比较高。

c)、如果某一个分支预测错了，那么开销也是比较大的。

**2、限制并行计算性能的因素**

a)、不同核的通信成本

b)、不同核的工作负载

### 单指令流

![1552749919690](C:\Users\yupei\AppData\Local\Temp\1552749919690.png)

上图所示，因为在CPU中只有一个取指/译码单元核ALU执行单元，因此都是每一个时钟周期执行一条指令。（当然在这过程中是由流水线存在的）

### 多指令流（Superscalar处理器）

![1552750137367](C:\Users\yupei\AppData\Local\Temp\1552750137367.png)

Superscalar处理器中有两个取指/译码单元和两个ALU执行单元，因此该处理器在一个时钟周期内可以执行两条指令，但是在我们大圈的地方并没有指令级并行，因为都是执行一条指令。

### 多核时代之前的处理器

![1552750344080](C:\Users\yupei\AppData\Local\Temp\1552750344080.png)

提高单指令流运行速度的手段：

1、更大的数据缓存

2、更加智能的乱序控制逻辑

3、更加智能的分支预测器

4、更多的内存预取

一般，这些手段最终都会归结到处理器需要更多的transistor，这就意味着要更高的时钟频率。

### 多核时代的处理器

![1552750514208](C:\Users\yupei\AppData\Local\Temp\1552750514208.png)

多核时代的处理器的设计思想是能不能让一个处理器上有更多的核，每个核执行指令的速度可以慢一些，但是可以通过利用多核并行的技术来加快程序运行速度。

### 想法1：多线程执行

第一个想到的并行计算技术应该就是多线程技术了，我们可以将代码中的for循环部分拆分成若干份互不相干的部分，然后由每一个线程来执行一个部分的逻辑。

### 想法2：增加ALU

因为我们经常发现程序中的for循环其实都是相互独立的，而且指令都是一样的，所以我们就考虑能不能增加ALU个数来并行的运行这些指令。这种技术叫做SIMD（Single instruction， multiple data），这里需要注意的一点是相同的指令会被广播到所有的ALU中，然后并行的执行这些指令。这里可以使用Intel的AVX指令来进行SIMD操作。

![1552751032359](C:\Users\yupei\AppData\Local\Temp\1552751032359.png)

我们可以看到每个核心有8个ALU，这样一次运行可以有128个元素可以被同时处理。

### SIMD中的条件执行

![1552751145605](C:\Users\yupei\AppData\Local\Temp\1552751145605.png)

如果我们的指令中有条件语句的话，那么会影响SIMD的性能，因为执行true部分ALU在运行的时候，执行false部分的ALU就会等着，然后到后面则反过来，执行false部分ALU在运行的时候，执行true部分的ALU就会等着。所以这会导致性能大大的降低。

### 相关术语

**指令流一致性**

1、所有的ALU应该要执行相同的指令。

2、指令一致性对SIMD的效率有着至关重要的作用。

3、如果是多核线程并行的话，那么指令一致就没啥必要。

**分歧执行**

指令流并不是一致性，比如有条件判断语句

### 现代CPU的SIMD执行

![1552751535354](C:\Users\yupei\AppData\Local\Temp\1552751535354.png)

1、使用一些CPU内部函数来显式的并行化。

2、需要C或者C++这种语言的支持。

 **explicit SIMD**：SIMD并行化在编译期就完成了。

### 并行执行总结

**多核：**提供线程级并行

**SIMD：**利用多个ALU来执行相同的指令流

**Superscalar：**利用指令流的ILP并行。（隐式并行）



### 内存访问的两个概念

1、**内存延迟：**将一条指令从内存中取出然后给处理器执行所花费的时间，一般我们都是使用100cycles，100nsec来表示。

2、**内存带宽：**内存在单位时间内可以给处理器提供数据的速率，比如单位为“GB/s”

### 处理器stall

如果当前指令需要依赖前一条指令而不能执行，那么我们就称为处理器stall，而访问内存是stall的一个重要来源。

![1552785351771](C:\Users\yupei\AppData\Local\Temp\1552785351771.png)

如上图所示，如果我们想要执行add这条指令，那么必须要等到内存[r2]和[r3]的数据加载到寄存器r0和r1中。而这个加载过程其实往往比较耗时间，所以会导致处理器stall。

### 缓存减少Latency

![1552785514144](C:\Users\yupei\AppData\Local\Temp\1552785514144.png)

我们增加缓存的作用就是要减少内存的访问时间（memory latency），具体是利用时间局部性和空间局部性这两大性质。

### 预取来减少Latency

现代的处理器都有预取数据的逻辑，它会动态的分析程序的访问模式，从而预测后面会访问哪些地方，然后先把数据取出来。当然了，如果我们预测错误的话，也会导致性能下降。

### 多线程来减少Latency

当某一个线程正在处理比较大的内存读取或者I/O开销的时候，我们可以让我们的线程交错执行，这样可以大大提高处理器的利用率，其实这只是一种隐藏Latency的方法，它在本质上并没有将Latency给减少。

### 吞吐率和计算权衡

![1552785971939](C:\Users\yupei\AppData\Local\Temp\1552785971939.png)

如上图所示，采用多线程我们可以提高整个系统的吞吐率，但是反过来我们会增加单独线程的运行时间，因为一些线程会把时间花在等待其他线程结束的过程。所以吞吐率和单独线程的计算需要有一定的权衡。

### 硬件支持多线程

这里的硬件支持多线程并不是我们之前所了解的操作系统支持的多线程，而是硬件支持的线程。一般在芯片中可以存储硬件上下文的区域并不大，这是一个有限的资源。

| <img src="C:\Users\yupei\AppData\Local\Temp\1552786465534.png" style="width:100px height:200px" /> | <img src="C:\Users\yupei\AppData\Local\Temp\1552786708117.png" style="width:100px height:200px" /> | <img src="C:\Users\yupei\AppData\Local\Temp\1552786822458.png" style="width:100px height:200px" /> |
| :----------------------------------------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: |
|                      8个ALU一个硬件线程                      |                     8个ALU，16个硬件线程                     |                     8个ALU，4个硬件线程                      |

**1、内核管理多线程的上下文**

处理器决定每个时钟周期要去执行什么线程的指令，以往这都是由操作系统来支持的。内核还是可以拥有相同的ALU资源，利用多线程的技术可以提高它们的利用效率，比如处理内存访问这种高延迟的动作。

**2、交错执行多线程**

每个时钟周期，处理器会选择一个线程来进行执行，这里只是一个并发的手段。

**3、同时执行多线程(SMT)**

每个时钟周期可以让多个线程指令的在ALU上同时执行，这相当于CPU的superscalar的扩充。比如英特尔处理器芯片的超线程就是这种技术。

### 多线程总结

**优点**

可以更好的利用ALU这些计算资源，同时可以隐藏内存延迟。

**缺点**

1、要求额外的存储区域用来存储线程的上下文

2、会增加每个线程的运行时间

3、要求独立的任务数要比ALU数目多，这样才可以发挥多线程的优势，同时隐藏内存延迟。

4、严重依赖内存带宽（memory bandwidth）

多线程➡更大的工作集➡每个线程的缓存减小，所以在使用多线程的时候我们会更加频繁的访问内存，这给内存带宽带来压力，但是这可以隐藏内存延迟。

### 多核芯片分析

![1552787718930](C:\Users\yupei\AppData\Local\Temp\1552787718930.png)

| 核心数目 |   每个核的SIMD ALU   | 每个核的线程 | 并行指令流 | 并发指令流 |
| :------: | :------------------: | :----------: | :--------: | :--------: |
|    16    | 8个（整个芯片128个） |      4       |     16     |     64     |

关于并行指令流的意思，我们这里由16个核，所以同时只能执行16个指令流。而为什么并发数可以有64个呢？因为我们每个内核中有4个线程，所以这样一算来我们总共可以有64个并发指令流。

### GPUs：面向吞吐率设计的处理器

![1552789180860](C:\Users\yupei\AppData\Local\Temp\1552789180860.png)

**SM=core**

每一个黄色小块代表一个SIMD函数单元，一条指令可以在32个这样的单元上面同时执行。这32个单元组成一个warp，我们可以看上面SIMD单元以及warp分布。我们可以认为warp就是可以一个32宽的向量指令。1080的SM同时可以处理最多4个warp（相当于同时多线程，SMT）。那每个SM最多可以有64个warp，当然这64个并不是同时执行，而是并发执行，相关执行顺序要看调度算法。所以总共有64*32=2048个元素可以在SM中并发的执行。

### CPU核GPU的内存结构

![1552790163681](C:\Users\yupei\AppData\Local\Temp\1552790163681.png)

**CPU：**CPU有大量的缓存，主要是用来考虑内存延迟的，同时可以并行执行的线程比较少，因此我们的内存带宽也不是很大，整个CPU计算是比较依靠缓存以及预取技术的。**CPU更加关注低延迟**

**GPU：**GPU的缓存数目比较少，但是它的线程数目非常的多，同时内存的带宽也比较大，因为要服务这么多的线程。GPU是比较依赖于多线程执行的。**GPU更加关注吞吐率**

### 带宽受限的例子

![1552790717482](C:\Users\yupei\AppData\Local\Temp\1552790717482.png)

两个向量的加法运算的内存访问过程

1、将数据加载到A数组中

2、将数据加载到B数组中

3、计算A[i]×B[i]

4、将数据存到C中。



![1552791279262](C:\Users\yupei\AppData\Local\Temp\1552791279262.png)

相当于一个乘法操作需要12字节的数据量，上图是GTX 1080的布局图，图中总共有20*128=2560个ALU，频率为1.6GHz，所以每秒所作的运算次数有：2560×1.6×10^9=4.096×10^12，则每秒需要的数据量为4.096×10^12×12/（1024^4）=45TB/s，只有达到这样的内存带宽补充我们的ALU才会一致忙碌着计算而不会stall。但是反观我们的GPU，它只能提供320GB/s的内存带宽，所以GPU的真实计算效率连1%都不到，主要的原因还是内存带宽的限制，但还是要比一般的CPU处理数据的速度要块。其实，CPU和GPU都是收到了内存带宽不足这个问题，因为CPU计算实在太快了，而内存系统并不能快速的喂数据给CPU。

### 带宽是关键资源

1、计算的时候要尽量少的向内存访问数据，尽量使用之前已经加载的数据（像我们之前学习在缓存中利用时间局部性来读取数据可以优化计算），而且不同的线程如果访问相同的数据要尽量使用共享的方法共享数据，而不是再次从内存中读取数据。

2、计算密集型的程序可以更好的利用吞吐率高的处理器，因为计算密集型高的程序访问内存的次数比较少，可以节省大量的时间，而对于处理器来说，计算相当于是免费的。所以在设计程序中要尽量的多考虑计算密集型程序的使用。

### 总结

**现代处理器采用的3个主要思想**

1、在芯片上拥有更多的核，采用更多的线程级并行。

2、将指令流由多个ALU摊销，可以大大的提高计算能力。

3、利用多线程技术来有效的使用计算机的资源。

**由于目前的处理器的计算能力非常强悍，所以目前处理都存在带宽限制的问题（bandwidth bound）**

**GPU体系结构使用的适合CPU相同的吞吐率计算思想，但是GPU将这些概念推向了极端规模化，比如SIMD**

### 专业术语概念的理解

1、多核处理器：在一个处理器芯片中有多个处理单元。

2、SIMD执行：单个指令流，多个数据流动。CPU或者GPU通过一个fetch/decode模块来取指令，然后将其分发到多个ALU中进行计算。

3、一致控制流：在SIMD计算中，每个ALU执行的指令应该要一样，如果出现了条件语句的话会大大降低效率。

4、Interleaved multi-threading：这是硬件多线程的一种，一个核中可以有好几个线程，但这些线程是并发执行的而不是并行执行的。

5、Simultaneous multi-threading：这也是硬件多线程的一种，但是这些多线程可以同时的执行，是一种并行计算。intel处理器的超线程就是这种硬件多线程。

6、内存延迟：处理器发出数据请求到处理器获得数据的时间。单位为cycles

7、内存带宽：内存系统在单位时间内可以向处理器提供的数据量。单位为GB/s

8、带宽限制应用：由于目前的处理器的算术计算能力很强，所以处理器基本上受限于内存带宽。

9、Arithmetic intensity：计算的操作/内存访问的操作



### 计算模式演变

1、单个处理器执行（没有指令级并行），一次只能执行一条指令。

![1552794240927](C:\Users\yupei\AppData\Local\Temp\1552794240927.png)

2、superscalar执行（利用指令级并行），一次可以执行两条指令。

![1552794273250](C:\Users\yupei\AppData\Local\Temp\1552794273250.png)

3、多核处理器（每个核一次只能处理一条指令）

![1552794344769](C:\Users\yupei\AppData\Local\Temp\1552794344769.png)

4、多核+superscalar执行，每个核一次可以执行多条指令

![1552794401392](C:\Users\yupei\AppData\Local\Temp\1552794401392.png)

5、四核处理器，每个核心都有SIMD的ALU，每个SIMD单元要执行相同的指令。

![1552794661866](C:\Users\yupei\AppData\Local\Temp\1552794661866.png)

6、四核处理器，每个核心都有8个ALU，然后两个硬件线程，这样可以减少内存访问需要大量时间的问题了，当核心的一个指令流由于内存访问停住了，可以执行线程上下文切换，把另外一个指令流切入进行计算。



![1552794782355](C:\Users\yupei\AppData\Local\Temp\1552794782355.png)

7、四核处理器，每个核有superscalar、SIMD和硬件多线程。每个核一个时钟周期可以执行一个指令流中的两条指令（一条是SIMD指令、一条是scalar指令），当某一条指令流stall的时候可以通过硬件多线程的将另一个指令流调入ALU中进行计算。

![1552794990676](C:\Users\yupei\AppData\Local\Temp\1552794990676.png)

8、硬件线程和软件线程的区分：硬件线程一般是由核来管理的，每个核都有一块区域用于存储线程的上下文。而软件线程一般是由操作系统来管理的。通常来说软件线程的上下文切换要比硬件线程的上下文切换的成本高。

### 多线程交错运行

![1552795626032](C:\Users\yupei\AppData\Local\Temp\1552795626032.png)

如果我们的处理器只有一个fetch/decode和一个ALU，两个线程上下文存储区域。那么我们每次只能执行一条指令，那么这个核中的线程上下文切换会如上图所示。

### 多线程并行计算

![1552795747385](C:\Users\yupei\AppData\Local\Temp\1552795747385.png)

如果处理器有2个上下文先换区域，两个fetch/decode以及两个ALU，这样我们的处理器就可以执行超线程，每个线程用一个ALU、fetch/decode来执行指令（注意这里没有涉及到ILP，因为每个线程都是自己干自己的事情）



![1552795890688](C:\Users\yupei\AppData\Local\Temp\1552795890688.png)

这里我们将处理器中的上下文区域改为4个，那么我们一个核就可以有4个并发线程来同时执行了，但是由于我们只有两个fetch/decode以及ALU，所以要进行在并行执行的时候要进行交错执行。

### 线程并行计算+ILP并行

![1552796033400](C:\Users\yupei\AppData\Local\Temp\1552796033400.png)

其实有的时候两个ALU都是服务于同一个线程，那么一个线程的指令流可以有同时执行两条指令，这就是指令级并行的参与了。





































